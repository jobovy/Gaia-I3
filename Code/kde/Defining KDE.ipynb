{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a KDE Function to Evaluate Six Dimensional Position-Velocity Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is a KDE?**\n",
    "\n",
    "In a kernel density estimation, each point of data is transformed into individual kernels which combine together to give a smooth probability density function for the input parameter(s). This proves useful as a regular histogram-style density estimate would not be differentiable but a kernel density estimate is.\n",
    "\n",
    "**Using `sklearn.neighbors.KernelDensity`:**\n",
    "\n",
    "There are six kernels that are currently avaliable with this module (gaussian, tophat, epanechnikov, exponential, linear, cosine). The methods from this module that were used are as follows:\n",
    "\n",
    "`fit` takes in an NxM matrix of N data points and M parameters and fits them to the specified kernel and bandwidth.\n",
    "\n",
    "`score_samples` takes in an array of points that are being queried and applies these points to the previously `fit` data. The input would be a QxM matrix of Q sets of points and M parameters and the output gives a 1xQ array of logarithmic probabilities at each of the points.\n",
    "\n",
    "For more practical purposes the function converts the logarithmic probabilities to standard by taking an exponential. For the complete original documentation:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity\n",
    "\n",
    "**Optimizing the bandwidth and `scipy.stats.iqr`:**\n",
    "\n",
    "The bandwidth is optimized in terms of Scott's Rule of Thumb, which follows the model: \n",
    "\n",
    "$bw = {1.059}{(A)}{(N)}^{(-1/5)}$, where $A = min(std(X),\\frac{IQR}{1.34})$\n",
    "\n",
    "In this case X is the inputs (an NxM matrix of N points and M parameters) and the IQR is the difference between the 75th and 25th percentile of the data. It is a measure of the dispersion similar to standard deviation or variance, but is much more robust against outliers.\n",
    "\n",
    "To compute the IQR, we have used `scipy.stats.iqr` which takes inputs N and X, with N being the number of objects and X similarly defined as above. This outputs the IQR of our input data which is then used to compute the optimized bandwidth based on Scott's Rule of Thumb as defined above.\n",
    "\n",
    "**Regarding inputs and `v_scale`:**\n",
    "\n",
    "All inputs will have `v_scale` applied to their velocities before being put through the KDE function. This normalizes the vecloities and positions to similar magnitudes in 6 dimensional space. It is required as the velocities magnitudes are generally much larger and span a larger range than the positions as well as differing units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required modules\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import iqr\n",
    "\n",
    "#Defining a KDE function to quickly compute probabilities for the data set\n",
    "def generate_KDE(inputs, ker, v_scale):\n",
    "    \"\"\"\n",
    "    NAME:\n",
    "        generate_KDE\n",
    "    \n",
    "    PURPOSE:\n",
    "        Given an NxM matrix for inputs, one of six avaliable ker strings \n",
    "        and a float value for v_scale to output a function `input_DKE` \n",
    "        that treats the density estimate as a black box function that \n",
    "        can be sampled.\n",
    "    \n",
    "    INPUT:\n",
    "        inputs (ndarray) = An NxM matrix where N is the number of data \n",
    "                           points and M is the number of parameters.\n",
    "        ker (string) = One of the 6 avaliable kernel types (gaussian, \n",
    "                       tophat, epanechnikov, exponential, linear, cosine).\n",
    "        v_scale (float) = A float value to scale velocities for the kde.\n",
    "    \n",
    "    OUTPUT:\n",
    "        input_KDE (function) = A blackbox function for the density estimate\n",
    "                               used for sampling data.\n",
    "                               \n",
    "    HISTORY:\n",
    "        2018-06-14 - Updated - Ayush Pandhi\n",
    "    \"\"\"\n",
    "    #Scaling velocities with v_scale\n",
    "    positions, velocities = np.hsplit(inputs, 2)\n",
    "    velocities_scaled = velocities*v_scale\n",
    "    inputs = np.hstack((positions, velocities_scaled))\n",
    "    \n",
    "    #Optimizing bandwidth in terms of Scott's Rule of Thumb\n",
    "    shape_string = str(inputs.shape)\n",
    "    objects, parameters = shape_string.split(', ')\n",
    "    N_string = objects[1:]\n",
    "    N = int(N_string)\n",
    "    IQR = iqr(inputs)\n",
    "    A = min(np.std(inputs), IQR/1.34)\n",
    "    bw = 1.059 * A * N ** (-1/5.)\n",
    "    \n",
    "    #Fit data points to selected kernel and bandwidth\n",
    "    kde = KernelDensity(kernel=ker, bandwidth=bw).fit(inputs)  \n",
    "\n",
    "    def input_KDE(samples):\n",
    "        \"\"\"\n",
    "        NAME:\n",
    "            input_KDE\n",
    "    \n",
    "        PURPOSE:\n",
    "            Given a QxM matrix for samples, evaluates the blackbox density\n",
    "            estimate function at those points to output a 1xQ array of \n",
    "            density values.\n",
    "    \n",
    "        INPUT:\n",
    "            samples (ndarray) = A QxM matrix where Q is the number of points \n",
    "                                at which the kde is being evaluated and M is \n",
    "                                the number of parameters.\n",
    "                                \n",
    "        OUTPUT:\n",
    "            dens (ndarray) = A 1xQ array of density values for Q data points.\n",
    "                               \n",
    "        HISTORY:\n",
    "            2018-06-14 - Updated - Ayush Pandhi\n",
    "        \"\"\"\n",
    "        #To correct the type of information from other functions into acceptable input\n",
    "        samples = np.array([samples])\n",
    "        \n",
    "        #Scaling samples with v_scale\n",
    "        samp_positions, samp_velocities = np.hsplit(samples, 2)\n",
    "        samp_velocities_scaled = samp_velocities*v_scale\n",
    "        samples = np.hstack((samp_positions, samp_velocities_scaled))\n",
    "        \n",
    "        #Get the log density for selected samples and apply exponential to get normal probabilities\n",
    "        log_dens = kde.score_samples(samples)\n",
    "        dens = np.exp(log_dens)\n",
    "        \n",
    "        #Return a 1xQ array of normal probabilities for the selected sample\n",
    "        return dens\n",
    "    \n",
    "    #Return a black box function for sampling\n",
    "    return input_KDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section tests this function on some mock data. For more details about the setup for the mock data, see `sampling_R^6_to_R^6.ipynb` by Michael Poon. It is serves as a good example to see the shapes and types of inputs to avoid getting dimensional errors with the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 33.0, -300.0, 9.090909090909092, 2.0, 5.636363636363637], [1, 24.363636363636367, -222.2727272727273, 6.636363636363637, 5.454545454545455, 1.2727272727272727], [1, 46.727272727272734, -423.5454545454546, 7.818181818181818, 5.2727272727272725, 8.454545454545455], [1, 45.45454545454545, -412.0909090909091, 4.0, 4.909090909090909, 9.545454545454545], [1, 39.09090909090909, -354.81818181818187, 6.0, 8.09090909090909, 4.636363636363637], [1, 23.27272727272727, -212.45454545454544, 3.4545454545454546, 5.0, 2.2727272727272725], [1, 46.0, -417.0, 9.272727272727273, 2.0, 9.90909090909091], [1, 45.45454545454546, -412.0909090909091, 5.909090909090909, 4.090909090909091, 9.454545454545455], [1, 41.54545454545455, -376.90909090909093, 2.8181818181818183, 7.363636363636364, 7.0], [1, 56.54545454545455, -511.90909090909093, 5.363636363636363, 9.090909090909092, 10.0]]\n"
     ]
    }
   ],
   "source": [
    "#Testing with mock data\n",
    "import random\n",
    "\n",
    "mock_data3 = []\n",
    "for i in range(10):\n",
    "    select_random = np.linspace(1.0, 10.0, 100)\n",
    "    x4 = random.choice(select_random)\n",
    "    x5 = random.choice(select_random)\n",
    "    x6 = random.choice(select_random)\n",
    "    x1 = 1\n",
    "    x2 = 3 + x4 + 2*x5 + 3*x6 \n",
    "    x3 = -3 - 2*x2 - 3*x2 - 4*x2\n",
    "    mock_data3.append([x1, x2, x3, x4, x5, x6])\n",
    "print(mock_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.        ,   44.45454545, -403.09090909,    2.        ,\n",
       "           6.36363636,    8.90909091],\n",
       "       [   1.        ,   44.        , -399.        ,    1.        ,\n",
       "           7.18181818,    8.54545455],\n",
       "       [   1.        ,   47.90909091, -434.18181818,    1.81818182,\n",
       "           9.54545455,    8.        ],\n",
       "       [   1.        ,   26.        , -237.        ,    5.        ,\n",
       "           3.81818182,    3.45454545],\n",
       "       [   1.        ,   37.09090909, -336.81818182,    1.54545455,\n",
       "           2.90909091,    8.90909091],\n",
       "       [   1.        ,   44.45454545, -403.09090909,    7.09090909,\n",
       "           9.        ,    5.45454545],\n",
       "       [   1.        ,   32.81818182, -298.36363636,    1.09090909,\n",
       "           4.27272727,    6.72727273],\n",
       "       [   1.        ,   35.81818182, -325.36363636,    2.72727273,\n",
       "           9.45454545,    3.72727273],\n",
       "       [   1.        ,   23.27272727, -212.45454545,    8.09090909,\n",
       "           3.63636364,    1.63636364],\n",
       "       [   1.        ,   26.81818182, -244.36363636,    7.27272727,\n",
       "           1.72727273,    4.36363636]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(mock_data3)\n",
    "samples_random = [[1, 2, 3, 4, 5, 6]]\n",
    "b = np.array(samples_random)\n",
    "samples_all = [[1, 44.45454545454545, -403.0909090909091, 2.0, 6.363636363636364, 8.90909090909091], [1, 44.0, -399.0, 1.0, 7.181818181818182, 8.545454545454547], [1, 47.90909090909091, -434.18181818181813, 1.8181818181818183, 9.545454545454545, 8.0], [1, 26.0, -237.0, 5.0, 3.8181818181818183, 3.4545454545454546], [1, 37.09090909090909, -336.81818181818187, 1.5454545454545454, 2.909090909090909, 8.90909090909091], [1, 44.45454545454545, -403.0909090909091, 7.090909090909091, 9.0, 5.454545454545455], [1, 32.81818181818182, -298.3636363636364, 1.0909090909090908, 4.272727272727273, 6.7272727272727275], [1, 35.81818181818182, -325.3636363636364, 2.7272727272727275, 9.454545454545455, 3.7272727272727275], [1, 23.272727272727273, -212.45454545454544, 8.09090909090909, 3.6363636363636362, 1.6363636363636362], [1, 26.81818181818182, -244.3636363636364, 7.2727272727272725, 1.7272727272727273, 4.363636363636363]]\n",
    "c = np.array(samples_all)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blackbox = generate_KDE(a, 'epanechnikov')\n",
    "blackbox(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
