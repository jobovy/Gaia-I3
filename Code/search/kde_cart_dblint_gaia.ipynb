{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.integrate import dblquad\n",
    "from galpy.util.bovy_coords import *\n",
    "from search_local import *\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "#Setting up the quasi-isothermal instance for galpy\n",
    "from galpy.df import quasiisothermaldf\n",
    "from galpy.potential import MWPotential2014\n",
    "from galpy.actionAngle import actionAngleStaeckel\n",
    "from galpy.actionAngle import actionAngleAdiabatic\n",
    "\n",
    "aAS= actionAngleStaeckel(pot=MWPotential2014,delta=0.45,c=True)\n",
    "qdfS= quasiisothermaldf(1./3.,0.2,0.1,1.,1.,pot=MWPotential2014,aA=aAS,cutcounter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing qdf load data\n",
    "gaia_data = search_phase_space(0., 0., 0., 0., 0., 0., 0.5, 0.)\n",
    "\n",
    "print('#stars', len(gaia_data))\n",
    "print('min/max/mean (x)', min(gaia_data[:,0]), max(gaia_data[:,0]), np.mean(gaia_data[:,0]))\n",
    "print('min/max/mean (y)', min(gaia_data[:,1]), max(gaia_data[:,1]), np.mean(gaia_data[:,1]))\n",
    "print('min/max/mean (z)', min(gaia_data[:,2]), max(gaia_data[:,2]), np.mean(gaia_data[:,2]))\n",
    "print('min/max/mean (vx)', min(gaia_data[:,3]), max(gaia_data[:,3]), np.mean(gaia_data[:,3]))\n",
    "print('min/max/mean (vy)', min(gaia_data[:,4]), max(gaia_data[:,4]), np.mean(gaia_data[:,4]))\n",
    "print('min/max/mean (vz)', min(gaia_data[:,5]), max(gaia_data[:,5]), np.mean(gaia_data[:,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the KDE function rather than importing to allow for quick and easy changes\n",
    "def generate_KDE(inputs, ker, bw_multiplier=10):\n",
    "    \"\"\"\n",
    "    NAME:\n",
    "        generate_KDE\n",
    "    \n",
    "    PURPOSE:\n",
    "        Given an NxM matrix for inputs and one of six avaliable ker strings, \n",
    "        outputs a function `input_DKE` that treats the density estimate as a \n",
    "        black box function that can be sampled.\n",
    "    \n",
    "    INPUT:\n",
    "        inputs (ndarray) = An NxM matrix where N is the number of data \n",
    "                           points and M is the number of parameters.\n",
    "        ker (string) = One of the 6 avaliable kernel types (gaussian, \n",
    "                       tophat, epanechnikov, exponential, linear, cosine).\n",
    "        selection = a selection function that takes parallax to Sun and returns\n",
    "                    fraction of stars that are left after selection;\n",
    "                    takes array; takes parallax in physical units\n",
    "    \n",
    "    OUTPUT:\n",
    "        input_KDE (function) = A blackbox function for the density estimate\n",
    "                               used for sampling data.\n",
    "                               \n",
    "    HISTORY:\n",
    "        2018-07-15 - Updated - Ayush Pandhi\n",
    "    \"\"\"\n",
    "    #Scaling velocities with z-score\n",
    "    inputs_std = np.nanstd(inputs, axis=0)\n",
    "    i1, i2, i3, i4, i5, i6 = np.mean(inputs, axis=0)\n",
    "    inputs_mean = np.hstack((i1, i2, i3, i4, i5, i6))\n",
    "    inputs = (inputs - inputs_mean)/inputs_std\n",
    "    \n",
    "    #Optimizing bandwidth in terms of Scott's Multivariate Rule of Thumb\n",
    "    N = inputs.shape[0]\n",
    "    bw = bw_multiplier * np.nanstd(inputs) * N ** (-1/10.)\n",
    "    \n",
    "    #Fit data points to selected kernel and bandwidth\n",
    "    kde = KernelDensity(kernel=ker, bandwidth=bw).fit(inputs)  \n",
    "    \n",
    "    def input_KDE(samples):\n",
    "        \"\"\"\n",
    "        NAME:\n",
    "            input_KDE\n",
    "    \n",
    "        PURPOSE:\n",
    "            Given a QxM matrix for samples, evaluates the blackbox density\n",
    "            estimate function at those points to output a 1xQ array of \n",
    "            density values.\n",
    "    \n",
    "        INPUT:\n",
    "            samples (ndarray) = A QxM matrix where Q is the number of points \n",
    "                                at which the kde is being evaluated and M is \n",
    "                                the number of parameters.\n",
    "                                \n",
    "        OUTPUT:\n",
    "            dens (ndarray) = A 1xQ array of density values for Q data points.\n",
    "                               \n",
    "        HISTORY:\n",
    "            2018-07-15 - Updated - Ayush Pandhi\n",
    "        \"\"\"      \n",
    "        #Converting cylindrical samples to cartesian\n",
    "        x, y, z = cyl_to_rect(samples[:,0], samples[:,1], samples[:,2])\n",
    "        vx, vy, vz = cyl_to_rect_vec(samples[:,3], samples[:,4], samples[:,5], samples[:, 1])\n",
    "        samples = np.stack((x, y, z, vx, vy, vz), axis=1)\n",
    "        \n",
    "        #Scaling samples with standard deviation\n",
    "        samples = (samples - inputs_mean)/inputs_std\n",
    "        \n",
    "        #Get the log density for selected samples and apply exponential to get normal probabilities\n",
    "        log_dens = kde.score_samples(samples)\n",
    "        dens = np.exp(log_dens)\n",
    "        \n",
    "        #Return a 1xQ array of normal probabilities for the selected sample\n",
    "        return dens\n",
    "    \n",
    "    #Return a black box function for sampling\n",
    "    return input_KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate kde for 6D qdf inputs\n",
    "kde_gaia_epanechnikov = generate_KDE(gaia_data, 'epanechnikov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input values for velocities (vR, vT, vz)\n",
    "v_input = np.linspace(-400, 200, 100)\n",
    "\n",
    "# -----------------\n",
    "# Integrate over vR\n",
    "# -----------------\n",
    "\n",
    "def kde_gaia_cyl_vR(vT, vz, R, phi, z, vR):\n",
    "    evaluation = kde_gaia_epanechnikov(np.array([[R, phi, z, vR, vT, vz]]))\n",
    "    return evaluation\n",
    "\n",
    "def integrate_over_vR(kde_gaia_epanechnikov, vR): #bounds of vT = [-300, 0], bounds of vz = [-100, 100]\n",
    "    print (\"Evaluating at vR =\", vR)\n",
    "    return dblquad(kde_gaia_cyl_vR, -300, 0, -100, 100, args=([8.3, 3.14, 0., vR]), epsabs=0.001)  # args=(R, phi, z, vR)\n",
    "\n",
    "vR_output = np.ones([100])\n",
    "\n",
    "print(\"With R, phi, z = 8.3, 3.14, 0., integrating over vT from [=300, 0] and vz from [-100, 100].\")\n",
    "print(\"KDE Evaluations along vR from [-400, 200] over 100 subintervals.\")\n",
    "print()\n",
    "\n",
    "counter = 0\n",
    "start_overall = time.time()\n",
    "\n",
    "for v in np.nditer(v_input):\n",
    "    counter += 1\n",
    "    print(\"Evaluation:\", counter)\n",
    "    start = time.time()\n",
    "    vR_output[counter - 1], error = integrate_over_vR(kde_gaia_epanechnikov, v)\n",
    "    print(\"Value:\", vR_output[counter - 1])\n",
    "    end = time.time()\n",
    "    print(\"Time to integrate: \"'{}'\"s\".format(round(end - start, 2)))\n",
    "    print(\"Time elapsed: \"'{}'\" min\".format(round((end - start_overall)/60, 2)))\n",
    "    print()\n",
    "    \n",
    "# -----------------\n",
    "# Integrate over vT\n",
    "# -----------------\n",
    "\n",
    "def kde_gaia_cyl_vT(vR, vz, R, phi, z, vT):\n",
    "    evaluation = kde_gaia_epanechnikov(np.array([[R, phi, z, vR, vT, vz]]))\n",
    "    return evaluation\n",
    "\n",
    "def integrate_over_vT(kde_gaia_epanechnikov, vT): #bounds of vR = [-100, 100], bounds of vz = [-100, 100]\n",
    "    print (\"Evaluating at vT =\", vT)\n",
    "    return dblquad(kde_gaia_cyl_vT, -100, 100, -100, 100, args=([8.3, 3.14, 0., vT]), epsabs=0.01)  # args=(R, phi, z, vR)\n",
    "\n",
    "vT_output = np.ones([100])\n",
    "\n",
    "print(\"With R, phi, z = 8.3, 3.14, 0., integrating over vR from [-100, 100] and vz from [-100, 100].\")\n",
    "print(\"KDE Evaluations along vT from [-400, 200] over 100 subintervals.\")\n",
    "print()\n",
    "\n",
    "counter = 0\n",
    "start_overall = time.time()\n",
    "\n",
    "for v in np.nditer(v_input):\n",
    "    counter += 1\n",
    "    print(\"Evaluation:\", counter)\n",
    "    start = time.time()\n",
    "    vT_output[counter - 1], error = integrate_over_vT(kde_gaia_epanechnikov, v)\n",
    "    print(\"Value:\", vT_output[counter - 1])\n",
    "    end = time.time()\n",
    "    print(\"Time to integrate: \"'{}'\"s\".format(round(end - start, 2)))\n",
    "    print(\"Time elapsed: \"'{}'\" min\".format(round((end - start_overall)/60, 2)))\n",
    "    print()\n",
    "    \n",
    "# -----------------\n",
    "# Integrate over vz\n",
    "# -----------------\n",
    "\n",
    "def kde_gaia_cyl_vz(vR, vT, R, phi, z, vz):\n",
    "    evaluation = kde_gaia_epanechnikov(np.array([[R, phi, z, vR, vT, vz]]))\n",
    "    return evaluation\n",
    "\n",
    "def integrate_over_vz(kde_gaia_epanechnikov, vz): #bounds of vR = [-100, 100], bounds of vT = [-300, 0]\n",
    "    print (\"Evaluating at vz =\", vz)\n",
    "    return dblquad(kde_gaia_cyl_vz, -100, 100, -300, 0, args=([8.3, 3.14, 0., vz]), epsabs=0.001)  # args=(R, phi, z, vR)\n",
    "\n",
    "vz_output = np.ones([100])\n",
    "\n",
    "print(\"With R, phi, z = 8.3, 3.14, 0., integrating over vR from [-100, 100] and vT from [0, 300].\")\n",
    "print(\"KDE Evaluations along vz from [-400, 200] over 100 subintervals.\")\n",
    "print()\n",
    "\n",
    "counter = 0\n",
    "start_overall = time.time()\n",
    "\n",
    "for v in np.nditer(v_input):\n",
    "    counter += 1\n",
    "    print(\"Evaluation:\", counter)\n",
    "    start = time.time()\n",
    "    vz_output[counter - 1], error = integrate_over_vz(kde_gaia_epanechnikov, v)\n",
    "    print(\"Value:\", vz_output[counter - 1])\n",
    "    end = time.time()\n",
    "    print(\"Time to integrate: \"'{}'\"s\".format(round(end - start, 2)))\n",
    "    print(\"Time elapsed: \"'{}'\" min\".format(round((end - start_overall)/60, 2)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_data2 = search_phase_space(0., 0., 0., 0., 0., 0., 0.05, 0.)\n",
    "R, phi, z = rect_to_cyl(gaia_data2[:,0], gaia_data2[:,1], gaia_data2[:,2])\n",
    "vR, vT, vz = rect_to_cyl_vec(gaia_data2[:,3], gaia_data2[:,4], gaia_data2[:,5], gaia_data2[:,0], gaia_data2[:,1], gaia_data2[:,2])\n",
    "gaia_data2 = np.stack((R, phi, z, vR, vT, vz), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize mean values for (R, vR, vT, z, vz)\n",
    "mR,mz = 8.3/8. ,0./8. #convert to nat. units\n",
    "\n",
    "vRs= np.linspace(-1,1,100) #odd endpoints because galpy uses natural units\n",
    "vTs= np.linspace(0,2,100)\n",
    "vzs= np.linspace(-1,1,100)\n",
    "\n",
    "#Calculating the probability of vR without regard for vT or vz \n",
    "#is called marginalizing over the remaining probabilities.\n",
    "#This is the opposite of conditional probability. \n",
    "\n",
    "pvR= np.array([qdfS.pvR(vR,mR,mz) for vR in vRs]) #uses Gauss-Legendre integration\n",
    "pvT= np.array([qdfS.pvT(vT,mR,mz) for vT in vTs])\n",
    "pvz= np.array([qdfS.pvz(vz,mR,mz) for vz in vzs])\n",
    "\n",
    "#plot!\n",
    "fig, ax = plt.subplots(1, 3, sharex='none', sharey='none', figsize=(20,5))\n",
    "\n",
    "ax[0].plot(vRs*220, pvR/np.sum(pvR)/(vRs[1]-vRs[0])/220) #convert to physical units and normalize area to 1 \n",
    "ax[0].set_title('vR', fontsize=20)\n",
    "ax[1].plot(vTs*220, pvT/np.sum(pvT)/(vTs[1]-vTs[0])/220)\n",
    "ax[1].set_title('vT', fontsize=20)\n",
    "ax[2].plot(vRs*220, pvz/np.sum(pvR)/(vzs[1]-vzs[0])/220)\n",
    "ax[2].set_title('vz', fontsize=20)\n",
    "\n",
    "\n",
    "#above graphs overlayed\n",
    "vs= np.linspace(-1,2,100)\n",
    "\n",
    "pvR= np.array([qdfS.pvR(v,mR,mz) for v in vs])\n",
    "pvT= np.array([qdfS.pvT(v,mR,mz) for v in vs])\n",
    "pvz= np.array([qdfS.pvz(v,mR,mz) for v in vs])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.plot(vs*220, pvR/np.sum(pvR)/(vs[1]-vs[0])/220, label='vR') #convert to physical units and normalize area to 1 \n",
    "ax.plot(vs*220, pvT/np.sum(pvT)/(vs[1]-vs[0])/220, label='vT')\n",
    "ax.plot(vs*220, pvz/np.sum(pvz)/(vs[1]-vs[0])/220, label='vz')\n",
    "ax.hist(vR, bins=100, normed=True, label='vR_histogram', alpha=0.5)\n",
    "ax.hist(vT, bins=100, normed=True, label='vT_histogram', alpha=0.5)\n",
    "ax.hist(vz, bins=100, normed=True, label='vz_histogram', alpha=0.5)\n",
    "legend = ax.legend(loc='upper left', shadow=True, fontsize='x-large')\n",
    "legend.get_frame().set_facecolor('#F0F0F0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overplotting qdf and kde integrated\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax.plot(v_input, vR_output/np.sum(vR_output)/(v_input[1]-v_input[0]), label='vR_kde_integrated') #normalized area to 1\n",
    "ax.plot(v_input, vT_output/np.sum(vT_output)/(v_input[1]-v_input[0]), label='vT_kde_integrated')\n",
    "ax.plot(v_input, vz_output/np.sum(vz_output)/(v_input[1]-v_input[0]), label='vz_kde_integrated')\n",
    "ax.plot(vs*220, pvR/numpy.sum(pvR)/(vs[1]-vs[0])/220, label='vR_qdf_integrated')\n",
    "ax.plot(vs*220, pvT/numpy.sum(pvT)/(vs[1]-vs[0])/220, label='vT_qdf_integrated')\n",
    "ax.plot(vs*220, pvz/numpy.sum(pvz)/(vs[1]-vs[0])/220, label='vz_qdf_integrated')\n",
    "ax.hist(vR, bins=100, normed=True, label='vR_histogram', alpha=0.5)\n",
    "ax.hist(vT, bins=100, normed=True, label='vT_histogram', alpha=0.5)\n",
    "ax.hist(vz, bins=100, normed=True, label='vz_histogram', alpha=0.5)\n",
    "legend = ax.legend(loc='upper left', shadow=True, fontsize='x-large')\n",
    "legend.get_frame().set_facecolor('#F0F0F0')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
